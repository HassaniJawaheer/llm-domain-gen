{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53cd6d5f",
   "metadata": {},
   "source": [
    "# **Domain Generator — Business Dataset Creation** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda1961-3682-4aa8-8132-8028ce9b0d69",
   "metadata": {},
   "source": [
    "> To keep the notebook from becoming too long, most of the code for training, evaluation, and other tasks was moved into modules, which can be found in the project’s directories and are referenced in the imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754b424",
   "metadata": {},
   "source": [
    "## **Domain Dataset Generation (Groq API)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf01cb",
   "metadata": {},
   "source": [
    "> To create the dataset, I used an Grop API that is free for now. I chose the LLaMA 3 70B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba604ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from create_datasets.domain_dataset import DomainDataset\n",
    "\n",
    "#generator = DomainDataset(from_scratch=False)\n",
    "#generator.generate(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54999b7c-1776-492b-ade5-1ce200011466",
   "metadata": {},
   "source": [
    "> I used a prompt to generate fictionals companies along with a fictional business description. For each company description, the model provided five domain names.\n",
    "> Two points are important here. First, due to Grop API limitations, I cannot generate all the data I need in a single call, or even in just a few calls. I have to make multiple API requests to reach a sufficient dataset size, so I worked in iterations. In this case, I stopped at iteration 42. Each time new data is added, the dataset version number automatically increases.\n",
    "> Second, since I make multiple calls, some companies appear multiple times — and indeed, some do — but with slightly different descriptions and different domain names. Later in this document, I will explain how I handled this to avoid introducing bias into the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc85ec7-aa25-472e-ace2-f0121f2ce676",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c4459f-8b48-48c6-9a56-fa50f5836904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.data_processing import load_json_dataset\n",
    "\n",
    "model_path = \"model-based\"\n",
    "data_path = \"data/attempt_0/domain_dataset_v42.json\"\n",
    "\n",
    "data = load_json_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3449a04a-e77f-4c16-bed0-284350e47357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_description': 'EcoCycle is a startup that specializes in recycling and upcycling of electronic waste. Their goal is to reduce the massive amounts of e-waste that end up in landfills every year and promote sustainable living. They partner with companies and organizations to collect and process electronic waste, converting it into raw materials that can be used to manufacture new products.',\n",
       "  'domain': ['ecocycle.co',\n",
       "   'recycleit.today',\n",
       "   'greenbytes.net',\n",
       "   'techrecycle.io']},\n",
       " {'business_description': 'FitFusion is a fitness studio that offers a unique blend of yoga, Pilates, and dance classes. Their expert instructors design fusion workouts that cater to different fitness levels, from beginners to advanced practitioners. Their studios are equipped with state-of-the-art equipment and provide a serene atmosphere for members to relax and rejuvenate.',\n",
       "  'domain': ['fitfusion.studio',\n",
       "   'fusionfitness.co',\n",
       "   'yogadance.co',\n",
       "   'pilatesplus.fit',\n",
       "   'movewithfusion.com']},\n",
       " {'business_description': 'DreamWeavers is a boutique interior design firm that specializes in creating bespoke homes and offices. Their team of experienced designers work closely with clients to understand their style and preferences, providing personalized solutions that reflect their unique personality. From concept to completion, DreamWeavers takes care of every detail to deliver stunning spaces that exceed client expectations.',\n",
       "  'domain': ['dreamweavers.design',\n",
       "   'bespokeinteriors.co',\n",
       "   'homedecorstudio.net',\n",
       "   'officedesign.expert',\n",
       "   'dwinteriors.com']}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c2d25f-dacb-428d-bfb3-84ce847187ff",
   "metadata": {},
   "source": [
    "## **Group data by company**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101919bf-3907-49ab-bd68-9ba140f82e3f",
   "metadata": {},
   "source": [
    "> Once the data generation was complete, I grouped the entries by company. Since the data is added per API call, it comes in as a list of dictionaries, each containing a business description and a list of domain names. I then grouped these entries by company so that each company has all its associated descriptions, along with the domain names linked to each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "560186dd-f7d0-4f80-bd97-051f2f4ea73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.data_processing import group_by_company\n",
    "data_grouped_by_company_name  = group_by_company(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc60f532-4079-44ad-87c2-c32a49bc7082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_description': 'EcoCycle is a startup that specializes in recycling and upcycling of electronic waste. Their goal is to reduce the massive amounts of e-waste that end up in landfills every year and promote sustainable living. They partner with companies and organizations to collect and process electronic waste, converting it into raw materials that can be used to manufacture new products.',\n",
       "  'domain': ['ecocycle.co',\n",
       "   'recycleit.today',\n",
       "   'greenbytes.net',\n",
       "   'techrecycle.io']},\n",
       " {'business_description': 'EcoCycle is a sustainable waste management company that provides innovative recycling solutions to households and businesses. Our mission is to reduce landfill waste and promote a greener future.',\n",
       "  'domain': ['ecocycle.io',\n",
       "   'greencycle.net',\n",
       "   'wastewarriors.co',\n",
       "   'recyclerevolution.com',\n",
       "   'sustainablewaste.com']}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grouped_by_company_name['EcoCycle'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455767b0-b907-4eee-bae3-621178d53192",
   "metadata": {},
   "source": [
    "## **Splitting raw data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d605145-8dc9-437c-9c5d-bbac817f3619",
   "metadata": {},
   "source": [
    "> Next, the data is split into training and test sets. With the system we implemented earlier, this ensures that a company appearing in the training set will not appear in the test set, preventing the model from simply reproducing domain names it has already seen — even if the descriptions are slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5b39da1-b5bc-4dd1-bed7-51857710ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.data_processing import split_data\n",
    "\n",
    "# Split flattened data into train and eval sets\n",
    "train_data, eval_data = split_data(data_grouped_by_company_name, test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c3c06-3333-4b98-9d56-1cdfcb9bff3d",
   "metadata": {},
   "source": [
    "## **Flatten data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fdc48-1a96-4e57-87ea-5d4eb09a6222",
   "metadata": {},
   "source": [
    "> I then flatten the data so that each description is associated with a single domain name. Since each description is linked to five domain names, I simply expand the dataset so that each description–domain pair becomes its own entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a310a12e-72ee-4928-b19a-9318a1a7c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.data_processing import flatten\n",
    "\n",
    "# Flatten data so each business description has one domain per item\n",
    "flatten_train_data = flatten(train_data)\n",
    "flatten_eval_data = flatten(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec05232-c9d3-4dbc-a3f6-d29446343136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_description': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'domain': 'mindfulmentor.co'},\n",
       " {'business_description': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'domain': 'mindfulcoaching.io'},\n",
       " {'business_description': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'domain': 'productivitypros.net'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2af875-6e7e-497d-bd03-693788e87553",
   "metadata": {},
   "source": [
    "## **Formatting data for Supervised Fine-tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59662bc0-1b11-4211-91ca-e80d4f5b74f0",
   "metadata": {},
   "source": [
    "> Next, the training and evaluation data were transformed into an input–output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60f04a59-05e6-49a6-86ca-5cf0b8641b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.data_processing import format_for_sft\n",
    "\n",
    "# Input-output formatting\n",
    "formatted_train_data = format_for_sft(flatten_train_data)\n",
    "formatted_eval_data = format_for_sft(flatten_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4df9c5e4-6969-4a79-85d6-c48758e96c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'output': 'mindfulmentor.co'},\n",
       " {'input': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'output': 'mindfulcoaching.io'},\n",
       " {'input': 'MindfulMentor is an online coaching service that provides personalized guidance on mindfulness, productivity, and goal-setting. Their certified coaches offer one-on-one sessions.',\n",
       "  'output': 'productivitypros.net'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583ce38-9a10-4c06-a5bd-0005eec6e3a4",
   "metadata": {},
   "source": [
    "## **Converting to HuggingFace Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec4bdf-dbe2-4533-b42f-d8743b935886",
   "metadata": {},
   "source": [
    "> Next, we convert the training and evaluation data into the Hugging Face Dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "316d3e0e-5f5c-4a8b-a76b-ab42a206718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 14849\n",
      "Number of evaluation samples: 3291\n",
      "Total number of samples: 18140\n"
     ]
    }
   ],
   "source": [
    "from train.data_processing import convert_to_dataset\n",
    "\n",
    "# Convert formatted data to HuggingFace Dataset format\n",
    "train_dataset = convert_to_dataset(formatted_train_data)\n",
    "eval_dataset = convert_to_dataset(formatted_eval_data)\n",
    "\n",
    "# Print number of samples for sanity check\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of evaluation samples:\", len(eval_dataset))\n",
    "print(\"Total number of samples:\", len(train_dataset) + len(eval_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d8882-c9f9-41fc-bf23-fc7a5ea05a27",
   "metadata": {},
   "source": [
    "## **Compute max train token length**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e74bb-bac2-4471-a736-2f5e077730be",
   "metadata": {},
   "source": [
    "> Next, we estimate the token length of the sequences to help fine-tune the training parameters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a741d13-cb64-4427-91ce-eb4259bae70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "  Max input token length : 79\n",
      "  Max output token length: 11\n",
      "\n",
      "Eval set:\n",
      "  Max input token length : 85\n",
      "  Max output token length: 10\n",
      "\n",
      "max_seq_length (train): 90\n",
      "max_seq_length (eval) : 95\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from train.data_processing import get_max_token_length\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Compute max token lengths for input and output fields\n",
    "max_train_input_len = get_max_token_length(train_dataset, tokenizer, \"input\")\n",
    "max_train_output_len = get_max_token_length(train_dataset, tokenizer, \"output\")\n",
    "max_eval_input_len = get_max_token_length(eval_dataset, tokenizer, \"input\")\n",
    "max_eval_output_len = get_max_token_length(eval_dataset, tokenizer, \"output\")\n",
    "\n",
    "# Display all lengths\n",
    "print(\"Train set:\")\n",
    "print(\"  Max input token length :\", max_train_input_len)\n",
    "print(\"  Max output token length:\", max_train_output_len)\n",
    "\n",
    "print(\"\\nEval set:\")\n",
    "print(\"  Max input token length :\", max_eval_input_len)\n",
    "print(\"  Max output token length:\", max_eval_output_len)\n",
    "\n",
    "# Total sequence lengths (input + output)\n",
    "print(\"\\nmax_seq_length (train):\", max_train_input_len + max_train_output_len)\n",
    "print(\"max_seq_length (eval) :\", max_eval_input_len + max_eval_output_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89660ae9-adf3-4b86-adac-c1af7f39346c",
   "metadata": {},
   "source": [
    "## **Tokenize train and eval datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e80903-fbb2-474a-911e-ec63543a9e1e",
   "metadata": {},
   "source": [
    "> Next, we tokenize the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40217acd-f4e5-468e-97c6-382bb8593336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefd8db3d41a4dd389907744173261f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8104f69222485c94251a58cd1406ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from train.data_processing import tokenize_for_sft\n",
    "\n",
    "tokenize_fn = partial(\n",
    "    tokenize_for_sft,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length = 100\n",
    ")\n",
    "\n",
    "# Tokenize train dataset\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "# Tokenize eval dataset\n",
    "tokenized_eval_dataset = eval_dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bb00cca-b894-4ca7-92ab-d8a645412f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [14683, 1007, 28755, 308, 271, 349, 396, 3270, 21464, 2372, 369, 5312, 3327, 1332, 15988, 356, 2273, 19965, 28725, 24504, 28725, 304, 5541, 28733, 15062, 28723, 6723, 20654, 25360, 2405, 624, 28733, 266, 28733, 538, 13912, 28723, 2273, 1007, 466, 271, 28723, 1115, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2273, 1007, 466, 271, 28723, 1115, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728699a6-6979-4ea4-b9af-b2d929d2e61c",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226da62-3ac9-4c65-aefe-55a9073489da",
   "metadata": {},
   "source": [
    "The training was launched using the parameters listed below, grouped into three categories: Training Parameters, Quantization Parameters, and LoRA Parameters.\n",
    "| Category | Parameter | Value |\n",
    "|----------|-----------|-------|\n",
    "| **Training** | num_train_epochs | 20 |\n",
    "|  | per_device_train_batch_size | 64 |\n",
    "|  | per_device_eval_batch_size  | 64 |\n",
    "|  | gradient_accumulation_steps | 4 |\n",
    "|  | eval_accumulation_steps  | 16 |\n",
    "|  | eval_strategy | steps |\n",
    "|  | eval_steps | 25 |\n",
    "|  | logging_steps | 25 |\n",
    "|  | save_steps | 25 |\n",
    "|  | learning_rate | 5e-5 |\n",
    "|  | weight_decay | 0.001 |\n",
    "|  | fp16 | False |\n",
    "|  | bf16 | True |\n",
    "|  | max_grad_norm | 0.3 |\n",
    "|  | max_steps | -1 |\n",
    "|  | warmup_ratio | 0.1 |\n",
    "|  | group_by_length | True |\n",
    "|  | lr_scheduler_type | cosine |\n",
    "|  | max_seq_length | 100 |\n",
    "|  | optimizer | paged_adamw_32bit |\n",
    "|  | metric_for_best_model | eval_loss |\n",
    "|  | load_best_model_at_end | True |\n",
    "|  | greater_is_better | False |\n",
    "|  | early_stopping_patience | 3 |\n",
    "|  | early_stopping_threshold | 0.001 |\n",
    "| **Quantization** | load_in_4bit | True |\n",
    "|  | bnb_4bit_quant_type | nf4 |\n",
    "|  | bnb_4bit_compute_dtype | bfloat16 |\n",
    "|  | bnb_4bit_use_double_quant | False |\n",
    "| **LoRA** | r | 8 |\n",
    "|  | lora_alpha | 16 |\n",
    "|  | bias | none |\n",
    "|  | task_type | CAUSAL_LM |\n",
    "|  | target_modules | q_proj, k_proj, v_proj, o_proj |\n",
    "|  | lora_dropout | 0.05 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09df0fd-4559-451d-9789-bc3854ce565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8024809f0fea43b88fe1d0163ee6edc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='225' max='1160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 225/1160 1:20:49 < 5:38:51, 0.05 it/s, Epoch 3/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>10.990600</td>\n",
       "      <td>7.469403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.439900</td>\n",
       "      <td>4.417335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.794200</td>\n",
       "      <td>3.455979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.264600</td>\n",
       "      <td>3.308002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.171100</td>\n",
       "      <td>3.292005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.122400</td>\n",
       "      <td>3.287942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.093000</td>\n",
       "      <td>3.297572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.051800</td>\n",
       "      <td>3.321847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.035800</td>\n",
       "      <td>3.335022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/sshfs-persistent_area/bazarre/llm-domain-gen-main/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from config.train_config import train_config\n",
    "from train.train_runner import train_model\n",
    "\n",
    "model, attempt_path = train_model(tokenized_train_dataset, tokenized_eval_dataset, train_config, models_dir = \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dc46e-c754-4b0d-ae15-b3fddf4a93ab",
   "metadata": {},
   "source": [
    "## **Evaluate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a4729-10d7-4e1b-8dd2-ef18b1ce68cd",
   "metadata": {},
   "source": [
    "> Next, inference is performed on the evaluation data to test the model. The results are first assessed using cosine similarity, and then a model or API is used to estimate the confidence score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7d42b-d3af-45d4-8e88-e053fbbea1fe",
   "metadata": {},
   "source": [
    "### **Predict domain name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2c7d48-95b6-4601-8d22-06a59877f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046a806160af4e0490ad5fb6b2b0507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Génération:   0%|          | 0/3291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate.generation_utils import generate\n",
    "\n",
    "prediction_eval_data = generate(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data = flatten_eval_data,\n",
    "    proportion = 1.0,\n",
    "    seed = 0,\n",
    "    max_new_tokens = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65465b07-a44d-4452-b23d-d46763a254cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_description': 'LumiStudio is a photography studio that specializes in portrait, wedding, and event photography. They offer customized photography packages and editing services.',\n",
       "  'generated_domain': 'photographyhug.com',\n",
       "  'raw_generation': 'photographyhug.com We provide photography services for'},\n",
       " {'business_description': 'LumiStudio is a photography studio that specializes in portrait, wedding, and event photography. They offer customized photography packages and editing services.',\n",
       "  'generated_domain': 'photorevivals.coourb.com',\n",
       "  'raw_generation': 'photorevivals.coourb.com'},\n",
       " {'business_description': 'LumiStudio is a photography studio that specializes in portrait, wedding, and event photography. They offer customized photography packages and editing services.',\n",
       "  'generated_domain': 'shutterstudio.net',\n",
       "  'raw_generation': 'shutterstudio.net 3Tango'},\n",
       " {'business_description': 'LumiStudio is a photography studio that specializes in portrait, wedding, and event photography. They offer customized photography packages and editing services.',\n",
       "  'generated_domain': 'eventimages.co',\n",
       "  'raw_generation': 'eventimages.co: – event images core)'},\n",
       " {'business_description': 'LumiStudio is a photography studio that specializes in portrait, wedding, and event photography. They offer customized photography packages and editing services.',\n",
       "  'generated_domain': 'photographiestore.com',\n",
       "  'raw_generation': 'photographiestore.com -, photography-store'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_eval_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393d3da-4edd-4238-8953-9d25d13dd345",
   "metadata": {},
   "source": [
    "### **Evaluate with similarity cosine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302b6adb-1667-4e8b-b228-f8888789b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a32822a3c642b49901b180f6117d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Évaluation:   0%|          | 0/3291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus Similarity Mean : 0.8084388961910803\n"
     ]
    }
   ],
   "source": [
    "from evaluate.similarity_score import SimilarityScorer\n",
    "\n",
    "scorer = SimilarityScorer()\n",
    "\n",
    "mean_score, scores = scorer.evaluate_batch(\n",
    "    data = prediction_eval_data,\n",
    "    proportion = 1.0\n",
    ")\n",
    "print(f\"Cosinus Similarity Mean : {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26cd7f-89c9-47e0-8875-14bdb84a0aeb",
   "metadata": {},
   "source": [
    "> Once the predictions are made, cosine similarity is used to evaluate the semantic closeness between the description and the domain name generated by the model. This approach has limitations, as a deliberately lightweight model (`intfloat/e5-small-v2`) was chosen to avoid memory constraints. The main goal is simply to check whether the generated domain is at least somewhat semantically related to the description. This method is also interesting as a low-cost alternative to using an API, which can be expensive. Although there was also the idea of using the Groq API to generate the data, the plan later involves using GPT-4. As seen above, scores can become quite high because the model tends to reuse words from the description in the generated domain, which inflates the similarity score and reduces relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e977885-6b46-4e76-96a6-7e0444948c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Temporary save the prediction dataset\n",
    "#with open(\"prediction_eval_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    json.dump(prediction_eval_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2cdd6-42cb-454d-962d-965048934e5e",
   "metadata": {},
   "source": [
    "## **LLM as a Judge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33ecc50-2118-4889-9fc6-f777ceaa1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction data\n",
    "with open(\"prediction_eval_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prediction_eval_data =json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ef61982-6c4c-4e19-bca1-b8273d8ee69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 confidence Mean : 0.5364741641337372\n"
     ]
    }
   ],
   "source": [
    "from evaluate.llm_as_judge import evaluate\n",
    "\n",
    "mean_conf, scores = evaluate(\n",
    "    data=prediction_eval_data,\n",
    "    model_name=\"gpt-4\",\n",
    "    proportion=0.1,\n",
    "    seed=0,\n",
    "    temperature=0.0\n",
    ")\n",
    "print(f\"GPT-4 confidence Mean : {mean_conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74268491-141f-45b7-9135-9261ee2519b4",
   "metadata": {},
   "source": [
    "> Next, to evaluate the domains generated by the LLM, `gpt-4` was used. The evaluation was not run on the entire evaluation dataset; instead, a random sample was taken from the generated results. In this case, around 10% of the data was selected — roughly 300 description–domain pairs. Using the prompt defined in the `llm_as_a_judge.py` file located in the `evaluate` directory,`gpt-4` was asked to score the relevance of each generated domain to its corresponding description on a scale from 0 to 1. The resulting average confidence score was 0.54, which reflects the model’s performance and highlights certain limitations, as some generated domains were clearly irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "280b50b6-564d-48dd-9560-743510a2d819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_description': 'HomeHelp is a home maintenance and repair service that connects homeowners with trusted and experienced technicians. From plumbing to electrical work, HomeHelp has got it covered.',\n",
       "  'generated_domain': 'our',\n",
       "  'confidence': 0.1},\n",
       " {'business_description': 'PetalPushers is a flower delivery service that offers same-day delivery of fresh bouquets and arrangements. They source their flowers from local farmers to ensure the highest quality.',\n",
       "  'generated_domain': 'same-day-petal.com',\n",
       "  'confidence': 0.8},\n",
       " {'business_description': 'Provenance is a fine art gallery that showcases original works by emerging and established artists. Their exhibitions feature painting, sculpture, photography, and mixed media.',\n",
       "  'generated_domain': 'artsphere.net',\n",
       "  'confidence': 0.7},\n",
       " {'business_description': 'FreshFare is a meal kit delivery service providing healthy, pre-portioned ingredients and easy-to-follow recipes for home cooking. Their menu changes seasonally to ensure the freshest ingredients and flavors.',\n",
       "  'generated_domain': 'freshfarekit.com',\n",
       "  'confidence': 0.9},\n",
       " {'business_description': 'TerraTonic is a sustainable landscaping company that creates eco-friendly outdoor spaces for residential and commercial clients. Their team of experts uses native plants and innovative designs to reduce environmental impact.',\n",
       "  'generated_domain': 'sustainablespaces.net',\n",
       "  'confidence': 0.85}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30750e10-cdb9-4aaf-b4a7-efd7a652ce75",
   "metadata": {},
   "source": [
    "## **Save specific models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2d705-d4fd-4579-aca7-577a0cc975ef",
   "metadata": {},
   "source": [
    "> The final step is to save the weights of the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d73ef65-a178-44fd-ab27-3c945e384c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/weights/attempt_11/last_weights_evaluated'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train.train_utils import save_weights\n",
    "\n",
    "# after your training finishes\n",
    "save_dir = \"models/weights/attempt_11/last_weights_evaluated\"\n",
    "save_weights(model, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6e717-cb62-4aed-b59b-a47ceb3abf30",
   "metadata": {},
   "source": [
    "## **Merge Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14533d-8cb0-4763-a896-227e7b0516aa",
   "metadata": {},
   "source": [
    "> Finally, the weights are merged with the base model to produce the final fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86d2032d-1c24-48c0-963c-fece6a06c52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b20c9ce9dd4595a249c37afc46e6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: models/merged_models/Mistral-7B-v0.1-generate-domain_v4\n"
     ]
    }
   ],
   "source": [
    "from merge.merge_lora import merge\n",
    "import torch\n",
    "\n",
    "out = merge(\n",
    "    base_model_id=\"model-based\",\n",
    "    adapter_path=\"models/weights/attempt_11/last_weights_evaluated\",\n",
    "    output_base_path=\"./models/merged_models\",\n",
    "    use_case=\"generate-domain\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "print(\"Saved to:\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
